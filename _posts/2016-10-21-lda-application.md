--- 
layout: post 
title: LDA主题模型之模型应用
date: 2016-10-21 
categories: blog 
tags: [NLP, LDA] 
description: LDA应用
--- 

# LDA主题模型之模型应用

## 文档的相似度

### 概述

每篇文档用主题维度来表征，可以使用KL距离或者Lp距离来计算两个文档之间的相似度。

$$doc_similarity(d_1,d_2)=\sum_{k=0}^{K-1}(\sqrt{\theta_{k,d_1}}-\sqrt{\theta_{k,d_2}})^2$$

### 步骤

* 输入：训练好的LDA模型的theta文件。
* 为每个doc分别计算其他doc与该doc的主题距离（用上面的公式），再按照距离从小到大排序，输出每个doc最相关的前n个主题文章。

## 给文档分配主题

### 步骤

* 输入：训练好的LDA模型的theta文件和phi文件。
* 通过theta文件选取每篇文档的topn个主题，之后再每个主题中选取topm个词，作为该文档的主题。

## 网页推荐

在网上购物或者浏览新闻、帖子的时候，我们常常会看到给用户推荐一些相关的商品、新闻或者主题帖。实现推荐的方法有很多，其中比较流行的是采用LR对用户的点击率（CTR）进行预估，然后给该用户推荐其CTR高的网页。

这里，我们使用LDA进行特征集采，将每个网页的信息（比如新闻就是标题或正文，购物网站则是商品属性和简介，帖子则是帖子的内容）降维到K（主题数）维。之后使用Logistic模型进行训练。

> 注：一个用户的数据量由于非常有限，一般通过聚类/分类再处理，比如用聚类将用户进行划分，将相似属性的用户划分到一起，之后再对每一类用户进行LR模型训练。每类用户对应一个LR模型，之后有新的用户来时，可以先找到该用户的用户类，之后使用对应的LR模型进行预估和推荐。
> 特征增加一些用户的属性，比如是否被该用户点击过，用户的性别，年龄段，偏好等。

### 步骤

* 输入：网页数据和用户属性表。
* 利用网页数据训练LDA模型，得到各个网页的K维特征。
* 使用用户属性表进行用户聚类。
* 针对每个用户类，融合入该用户类的用户属性里提取的特征。
* 训练每个LR模型。

## 词排序

在上网的时候我们经常会根据关键词来检索相应的网页。那么如何做网页/商品的排序呢？传统的方法有按照关键词的TF-IDF值来对网页进行排序，或者使用PageRank推荐高质量的网页给用户。如果使用LDA，可以得到每个词的K维特征（K个主题），之后计算每个词和噪声词的距离来求得词的得分。

### 步骤

* 输入：一堆属于某类别的网页信息摘要。
* 使用LDA得到phi文件（V*K）。
* 对每个词的向量进行归一化。
* 计算每个词和噪声词的距离，即为得分。公式如下：
	* $$\vec{w_{noise}}=(\frac1K,\frac1K,...,\frac1K)$$
* 筛选出得分高的词，作为该类别的特征词。

## 话题排序

通过LDA获得的topic没有明确的含义，但是其内部的各个topic却隐含着不同的重要程度。现在我们需要衡量每个topic的重要程度（一般得分高的topic，其对应的词或者文章的相似度比较高）。

### 步骤

* 输入：LDA模型训练好的theta文件（D\*K）和phi文件（V\*K）。
* 使用theta文件得到每个topic的D维向量，并归一化。
* 使用phi文件得到每个topic的V维向量，并归一化。
* 分别用每个词的两个向量计算和对应的噪声向量的距离得分。分别得到$s_{td}$和$s_{tv}$。噪声向量分别为：
	* $$\vec{\theta_{noise}}=(\frac1D,\frac1D,...,\frac1D)$$
	* $$\vec{\phi_{noise}}=(\frac1V,\frac1V,...,\frac1V)$$
* 进行得分整合，比如可以按照如下公式：
	* $$s_{total}=a*s_{td}+(1-a)*s_{tv},a\subseteq[0,1]$$
* 按照$s_{total}$对每个topic进行排序。




## 参考

* 《LDA漫游指南》，这本书理论和实践结合的很棒。
